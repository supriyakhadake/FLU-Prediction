---
title: "FLU Prediction based on Symptoms"
output:
  html_notebook: default
  html_document: default
---

*Influenza Research Database (IRD) provides a resource for the influenza virus research community that facilitates an understanding of the influenza virus and how it interacts with the host organism, leading to new treatments and preventive actions.*

*Influenza, commonly known as "the flu", is an infectious disease caused by an influenza virus. High fever, runny nose, sore throat, headache, coughing, etc. are the most common symptoms. These symptoms typically begin two days after exposure to the virus and most last less than a week. Complications of influenza may include viral pneumonia, secondary bacterial pneumonia, sinus infections, and worsening of previous health problems such as asthma or heart failure. Once detected at an earlier stage based on the symptoms, the flu can be treated by getting plenty of rest, drinking plenty of liquids and, take medications to relieve the fever and muscle aches associated with the flu if necessary.*

*By applying statistical methods to this database, we would like to identify if a person is infected by FLU or not infected by FLU based on various factors such as symptoms exhibited by the patient.*

### Loading R-packages
```{r}
library(readxl)
library("rpart", lib.loc="C:/Program Files/R/R-3.3.3/library")
library("rpart.plot", lib.loc="~/R/win-library/3.3")
library("rattle", lib.loc="~/R/win-library/3.3")
library("RGtk2", lib.loc="~/R/win-library/3.3")
library("randomForest", lib.loc="~/R/win-library/3.3")
library(dplyr)
library(plotrix)
library(car)
library(rpart.plot)
library(rpart)
library(rattle)
library("ggplot2")
library("scales")
library("directlabels")
library("tidyr")
library("RColorBrewer")
library("ROCR")
library(randomForest)
library(class)

```
***

#### Loading dataset
```{r}
FluDB <- read_excel("C:/Users/Supriya Khadake/Desktop/SPRING 2018/ITMD 529/ITMD529_Project/Data/FluDB.xlsx")
```
***

#### Statistical description of the dataset
```{r}
summary(FluDB)
```
***

#### Assigning variables
```{r}
HostIdentifier = FluDB$HostIdentifier
FluDB$Location = as.factor(FluDB$Location)
FluDB$Age = FluDB$Age
FluDB$Gender = as.factor(FluDB$Gender)
FluDB$Temperature = FluDB$Temperature
FluDB$MedicalConditions = as.factor(FluDB$MedicalConditions)
FluDB$RunningNose = as.factor(FluDB$RunningNose)
FluDB$Cough = as.factor(FluDB$Cough)
FluDB$Myalgia = as.factor(FluDB$Myalgia)
FluDB$Headache = as.factor(FluDB$Headache)
FluDB$ThroatAche = as.factor(FluDB$ThroatAche)
FluDB$Fever = as.factor(FluDB$Fever)
FluDB$Fatigue = as.factor(FluDB$Fatigue)
FluDB$Vomiting = as.factor(FluDB$Vomiting)
FluDB$FluTestStatus = as.factor(FluDB$FluTestStatus)
```
***

#### Splitting data into train(70%) for model selection and test(30%) data for evaluation.
```{r}
set.seed(42)
FluDB=FluDB[sample(nrow(FluDB)),]
select.data= sample (1:nrow(FluDB), 0.7*nrow(FluDB))
train.data= FluDB[select.data,]
test.data= FluDB[-select.data,]
```
***

#### To display the number of rows for training and testing data
```{r}
nrow(test.data)
nrow(train.data)
```
***

#### Structure of the train data
```{r}
str(train.data)
```
***

#### Structure of the test data
```{r}
str(test.data)
```
***

### Exploratory Data Analysis 
Exploratory Data Analysis(EDA) is a critical step by which team discovered which parameters are most significant in determining the desired outcome. In our case we are trying to predict FLU based on symptoms and its more important to know which symptoms affect the most or if any of the symptom is least important and does not make any difference. With the help of plots for scenario of FluTestStatus as positive it was known that all of the 8 symptoms are relevant

#### Considering only patients having FLU
```{r}
FluDB_histogram=filter(FluDB,FluTestStatus==1)
```
***

### Quantitative Variables (Continuous Predictors)
Our current data includes Age and Temperature as Numeric variables. From the plots we observed that people within Age group 10 to 20 and temperature between 99 to 100 has FLU status as positive. Also, we saw that as Age increases the frequency of Flustatus being positive decreases
```{r, fig.width = 14, fig.height = 6.5}
par(mfrow=c(1,2))
hist_age = hist(FluDB_histogram$Age, col = "cyan4", xlab="Age", main = "Age group having FLU" )
text(hist_age$mids, hist_age$counts, labels = hist_age$counts, adj=c(0.5, -0.5))

hist_temp = hist(FluDB_histogram$Temperature, col="darkslategray3", xlab="Temperature", main = "Temperature of the patients infected by the FLU")   
text(hist_temp$mids, hist_temp$counts, labels = hist_temp$counts, adj=c(0.5, -0.5))
```
***

### Qualitative Variables (Categorical Predictors)
Histogram for Gender and Medical Conditions with Flu Status as positive:
We can see that female are more to have FLU status as positive and  medical condition does not affect that much. Also, Female are more susceptable to flu but differ against the range of men marginally
```{r fig.width = 8, fig.height = 6.5}
par(mfrow=c(1,2))
plot_gender = plot(FluDB_histogram$Gender,col="cyan4",xlab="Gender")
plot(FluDB_histogram$MedicalConditions,col="darkslategray3",xlab="Medical Conditions")
```
***

### Histogram for all the symptoms with Flu Status as positive:

This shows, most of these symptoms can indicate that a person is suffering from flu.
```{r fig.width = 12, fig.height = 6.5}

par(mfrow=c(1,4))
plot(FluDB_histogram$RunningNose,col="cyan4",xlab="Running Nose")
plot(FluDB_histogram$Cough,col="darkslategray3",xlab="Cough")
plot(FluDB_histogram$Myalgia,col="cyan4",xlab="Myalgia")
plot(FluDB_histogram$Headache,col="darkslategray3",xlab="Headache")

```
***

### Histogram for location with Flu Status as positive:
```{r fig.width = 12, fig.height = 6.5}

par(mfrow=c(1,4))
plot(FluDB_histogram$ThroatAche,col="cyan4",xlab="ThroatAche")
plot(FluDB_histogram$Fever,col="darkslategray3",xlab="Fever")
plot(FluDB_histogram$Fatigue,col="cyan4",xlab="Fatigue")
plot(FluDB_histogram$Vomiting,col="darkslategray3",xlab="Vomiting")
```
***

### Histogram for location with Flu Status as positive:
```{r fig.width = 14, fig.height = 6.5}

par(mfrow=c(1,1))
plot(FluDB_histogram$Location,col="cyan4",xlab="Location")
```
***

### Logistic Regression Model
Building model considering all the variables
```{r}
log0 = glm(FluTestStatus ~ Location + Age + Temperature + Gender + MedicalConditions + RunningNose + Cough
         + Myalgia + Headache + ThroatAche + Fever + Fatigue + Vomiting, data = train.data, family = "binomial")
summary(log0)
```
***

#### Without Location
By individual parameter we can see that location is not sugnificant to the response variable
Hence we will go ahead and eliminate the same and rebuild model.

```{r}
log1 = glm(FluTestStatus ~ Age + Temperature + Gender + MedicalConditions + RunningNose + Cough
+ Myalgia + Headache + ThroatAche + Fever + Fatigue + Vomiting, data = train.data, family = "binomial")
summary(log1)
```
***

#### Without Location & Eliminating Fatigue
```{r}
log2 = glm(FluTestStatus ~ Age + Temperature + Gender + MedicalConditions + RunningNose + Cough
+ Myalgia + Headache + ThroatAche + Fever + Vomiting, data = train.data, family = "binomial")
summary(log2)
```
***

#### Without Location & Eliminating ThroatAche
```{r}
log3 = glm(FluTestStatus ~ Age + Temperature + Gender + MedicalConditions + RunningNose + Cough
+ Myalgia + Headache + Fever + Vomiting, data = train.data, family = "binomial")
summary(log3)

```
***

#### Without Location & Eliminating Headache
We will stop here as we can see that all  variables are significant
```{r}
log4 = glm(FluTestStatus ~ Age + Temperature + Gender + MedicalConditions + RunningNose + Cough
+ Myalgia + Fever + Vomiting, data = train.data, family = "binomial")
summary(log4)
```
***

#### Calculating McFadden's R square value
```{r}
nullmodel=glm(FluDB$FluTestStatus~1,family="binomial")
1-logLik(log1)/logLik(nullmodel)
1-logLik(log2)/logLik(nullmodel)
1-logLik(log3)/logLik(nullmodel)
1-logLik(log4)/logLik(nullmodel)

```

***Model with highest Mc Fadden value is log1 which was the second model build with all variables as significant predictor variables except for location. And it was also the model with lowest AIC. Hence, as per both AIC and Mc Fadden we got model "log1" as the most fitted model***
***

#### Let's check multicollinearity for best model
```{r}
vif(log1)
```
***

### Decision Tree
```{r}
model10 = rpart(FluTestStatus ~ Age + Temperature + Gender + MedicalConditions + RunningNose + Cough+ Myalgia + Headache + ThroatAche + Fever + Fatigue + Vomiting, data = train.data, method = "class")
fancyRpartPlot(model10, cex=.58)
```
***

#### Constructing confusion matrix and checking accuracy of the model
```{r}
# Make predictions on the testing set -- Model10
my_prediction10 <- predict(model10, test.data, type = "vector")
# Finish the data.frame() call
my_solution10 <- data.frame(ID = test.data$HostIdentifier, flu10 = my_prediction10)
#Generation of Confusion Matrix
conf10 = table(test.data$FluTestStatus, my_solution10$flu10)
conf10
acc10 = sum(diag(conf10))/sum(conf10)
acc10

```
***

#### ROC Curve
```{r}
pred <- prediction(my_prediction10, test.data$FluTestStatus)

performance(pred, "auc")

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Decision Tree - Testing FluTestStatus")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                  label=paste("AUC =", round(au, 4)))
print(p)
```
***

### Random Forest
```{r}
my_forest_1 <- randomForest(FluTestStatus ~ Age + Temperature + MedicalConditions + RunningNose + Cough
+ Myalgia + Headache + ThroatAche + Fever + Fatigue + Vomiting, train.data, ntree=1000, importance=TRUE)
varImpPlot(my_forest_1)
```
***

#### Make predictions on the testing set - my_forest_1 without location
```{r}
my_prediction_1 <- predict(my_forest_1, test.data)
# Make predictions on the testing set -- my_forest_1
my_solution_1 <- data.frame(ID = test.data$HostIdentifier, forest1 = my_prediction_1)
#Generation of Confusion Matrix
conf_1 <- table(test.data$FluTestStatus,my_solution_1$forest1)
conf_1
acc_1 = sum(diag(conf_1))/sum(conf_1)
acc_1

```
***

### KNN Classifier
```{r}
train_label=train.data$FluTestStatus
test_label=test.data$FluTestStatus
```
***

```{r}
#Copying train and test data to knn_train and knn_test
knn_train <- train.data
knn_test <- test.data

```
***

```{r}
```
***

```{r}
#Dropping FLUTestStatus column for knn_train and knn_test
knn_train$FluTestStatus <- NULL
knn_test$FluTestStatus <- NULL

# Not Considering Location
knn_train$Location <- NULL
knn_test$Location <- NULL

# Not Considering HostIdentifier
knn_train$HostIdentifier <- NULL
knn_test$HostIdentifier <- NULL

#Normalizing Age
min_age <- min(knn_train$Age)
max_age <- max(knn_train$Age)
knn_train$Age <- (knn_train$Age - min_age)/(max_age - min_age)
knn_test$Age <- (knn_test$Age - min_age)/(max_age - min_age)

#Normalizing Temperature
max_temp <- max(knn_train$Temperature)
min_temp <- min(knn_train$Temperature)
knn_train$Temperature <- (knn_train$Temperature - min_temp)/(max_temp - min_temp)
knn_test$Temperature <- (knn_test$Temperature - min_temp)/(max_temp - min_temp)

# Determing best K-value using accuracy
range=1:round(0.2* nrow(knn_train))
accs= rep(0, length(range))
for(k in range) {knn_pred = knn(knn_train, knn_test, cl=train_label, k=k)
knn_conf <- table(test_label, knn_pred)
knn_conf
accs[k] = sum(diag(knn_conf))/sum(knn_conf)}
accs[k]
plot(range, accs, xlab="k")
which.max(accs)
```

#### From the above graph we can see that as value of k increases the Accuracy of the model decreases. The Accuracy of the model can be obtained highest at k = 1 to 5
Also, maximum accuracy obtained is at k = 3

Hence, checing for k = 10 and k = 3
From the below we proved that as value of k increases the accuracy of the model decreases
```{r}
knn_pred = knn(knn_train, knn_test, train_label, k=10, prob=TRUE)
knn_conf<- table(test_label, knn_pred)
knn_conf
sum(diag(knn_conf))/sum(knn_conf)

knn_pred1 = knn(knn_train, knn_test, train_label, k=3, prob=TRUE)
knn_conf1 <- table(test_label, knn_pred1)
knn_conf1 
sum(diag(knn_conf1))/sum(knn_conf1)

```

### Model Definition and Preparation
With respect to Logistic Regression we found that log1 model was the best model. Considering the variables used in log1 model, Decision Tree was built. We were able to obtain the accuracy of the model using Decision Tree as 98.23% and Random Forest as 99.60%. But before we finalize the model, we will check the quality of prediction that is being performed by our model. We will determine the odds of FluTestStatus and for that let us consider our equation that can be built from the model

Now, Considering p=P(Y=1) as probability of Y which is FluTestStatus. Hence we will set the threshold to 0.5 in order to determine the odds of Y happening
a)	For odd>1 then pr(Y=1) > Pr(Y=0) -> Pr(Y=1) > 0.5 
b)	For odd<1 then p=pr(Y=1) < Pr(Y=0) -> Pr(Y=1) < 0.5
c)	For odd=1 then Pr(Y=1) = Pr(Y=0) -> Pr(Y=1)=0.5 
We can do this by considering one row from the test.data

```{r}
head(test.data)
```

Considering row one, we will substitute these values in the equation obtained to determine the output.

Log(odds) = -146.46 + 0.08 * Age + 1.43 * Temperature + 0.99 * Gender1 -1.89 *MedicalConditions1 -3.74 * RunningNose1 + 1.96 * Cough1 + 2.85 * Myalgia1 - 2.57 * Headache1 - 0.32 * Throatache1 + 0.9 * Fever1 + 26.59 * Fatigue1 + 4.70 * Vomiting1.

Log(odds)= -2.104
```{r}
exp(-2.104)/1+exp(-2.104)
```

Since log(odds)=0.24 which is less than 1, The FluTestStatus for this scenario should be 0, which is as per the value in the data set. Hence, we can say that the prediction of our model is appropriate.

***Depending on the above models, we have decided the Random Forest performed better in terms of accuracy as it was giving the Highest Accuracy among Logistic Regression, Decision Tree & Random Forest.***

### Model Implementation 
FLUTestStatus = -146.46 + 0.08 * Age + 1.43 * Temperature + 0.99 * Gender1 -1.89 * MedicalConditions1 -3.74 * RunningNose1 + 1.96 * Cough1 + 2.85 * Myalgia1 - 2.57 * Headache1 - 0.32 * Throatache1 + 0.9 * Fever1 + 26.59 * Fatigue1 + 4.70 * Vomiting1